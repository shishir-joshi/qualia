{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9  ('qualia': venv)",
   "metadata": {
    "interpreter": {
     "hash": "9f216fef417bc6c42f31995dd72061a05be77532af677c96d7eb6f97a46421b7"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import transformers\n",
    "from embedding_model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model Compiled: stsb-distilbert-base\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained Model\n",
    "model = Model()\n",
    "model.make_pretrained('stsb-distilbert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "# Big JSON file \n",
    "import json\n",
    "arxiv = json.load(open('data/arxivData.json'))\n",
    "\n",
    "# Get it in line\n",
    "def join_ds(x, useful_keys):\n",
    "    return '. '.join([x[useful_keys[0]], x[useful_keys[1]]])\n",
    "\n",
    "# Keeping just the title and summary\n",
    "useful_keys = ['title', 'summary']\n",
    "arxiv_data = list(\n",
    "                map(lambda x: join_ds(x, useful_keys), \n",
    "                    arxiv\n",
    "                    )\n",
    "                )\n",
    "# Make numeric labels that correspond to the individual documents \n",
    "arxiv_data_labels = list(range(len(arxiv_data)))\n",
    "\n",
    "# Make Label to document mapping for pretty outputs\n",
    "label_mapping = dict(\n",
    "                    zip(arxiv_data_labels, \n",
    "                        arxiv_data\n",
    "                        )\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data to be added to the index:  29 (29, 768)\n"
     ]
    }
   ],
   "source": [
    "# Turn documents into vectors of dim (sample_len, 768)\n",
    "# Subselecting a few samples, \n",
    "i = 21\n",
    "sample_len = 50\n",
    "\n",
    "data_vec = model.encode_sentences(arxiv_data[i:sample_len])\n",
    "data_labels = arxiv_data_labels[i:sample_len]\n",
    "print(\"Data to be added to the index: \", len(data_labels), data_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Index from docs\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import hnswlib\n",
    "import numpy as np\n",
    "from utils import *\n",
    "\n",
    "# Parameters to initiate the HNSW Index\n",
    "HNSW_PARAMS = {\n",
    "    \"save_file\": 'hnsw_index.bin',\n",
    "    \"M\": 16,\n",
    "    \"ef_construction\": 200,\n",
    "    \"num_threads\": MAX_SEARCH_THREADS,\n",
    "    \"num_elements\": 50,\n",
    "    \"label_mapping\": label_mapping \n",
    "}\n",
    "\n",
    "from search_index import Index\n",
    "\n",
    "# Initiate the Search Index wrapper class \n",
    "hnsw_index = Index(HNSW_PARAMS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n        HNSW Index Params: \n            SAVE_DIR: /mnt/z/Project/semantic_search/qualia/model/v1/hnsw_index/,\n            SAVE_FILE: hnsw_index.bin,\n            CURR_IDX_SIZE: 49,\n            M: 16,\n            ef_construction: 200,\n            item_batch_size: 10,\n            num_threads: -1,\n            num_elements: 50,\n            index_loaded: False\n        \n"
     ]
    }
   ],
   "source": [
    "print(hnsw_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "First time?\nSaving Fresh New index: /mnt/z/Project/semantic_search/qualia/model/v1/hnsw_index/hnsw_index.bin\nSave index size: 10\nLoading saved index\n"
     ]
    }
   ],
   "source": [
    "# Create a new index with the given params and save it to given file \n",
    "hnsw_index.define_index(idx_size=10)\n",
    "hnsw_index.init_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n            Loading Previously saved index:\n                Loading File:     hnsw_index.bin\n                New max_elements: 39\n        \nAdding n=10 batches of items from the data\n29 29\nAdding keys to update list\nAdding keys to update list\nAdding keys to update list\nSaving new index of size 29\nSave index size: 29\n"
     ]
    }
   ],
   "source": [
    "# Add the data to the index\n",
    "hnsw_index.update_index(data_vec, data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NEAREST_NBRS = 5\n",
    "matches = hnsw_index.search(\n",
    "            model.encode_sentences(\n",
    "                \"reinforcement\"\n",
    "                ),\n",
    "            max_nearest_nbrs=MAX_NEAREST_NBRS\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "hnsw_index.get_current_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "len(matches['matches'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}